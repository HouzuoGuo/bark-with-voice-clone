{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Audio\n",
    "from scipy.io.wavfile import write as write_wav\n",
    "\n",
    "from bark.api import generate_audio\n",
    "from bark.generation import SAMPLE_RATE, preload_models, codec_decode, generate_coarse, generate_fine, generate_text_semantic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "semantic_path = \"semantic_output/pytorch_model.bin\" # set to None if you don't want to use finetuned semantic\n",
    "coarse_path = \"coarse_output/pytorch_model.bin\" # set to None if you don't want to use finetuned coarse\n",
    "fine_path = \"fine_output/pytorch_model.bin\" # set to None if you don't want to use finetuned fine\n",
    "use_rvc = True # Set to False to use bark without RVC\n",
    "rvc_name = 'howard-test'\n",
    "rvc_path = f\"Retrieval-based-Voice-Conversion-WebUI/assets/weights/{rvc_name}.pth\"\n",
    "index_path = f\"Retrieval-based-Voice-Conversion-WebUI/logs/{rvc_name}/added_IVF256_Flat_nprobe_1_{rvc_name}_v2.index\"\n",
    "device=\"cuda:0\"\n",
    "is_half=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading pth Retrieval-based-Voice-Conversion-WebUI/assets/weights/howard-test.pth\n",
      "<All keys matched successfully>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-20 20:30:39 | INFO | modules | Get sid: howard-test.pth\n",
      "2023-09-20 20:30:39 | INFO | modules | Loading: ./Retrieval-based-Voice-Conversion-WebUI/assets/weights/howard-test.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@@@@ instantiating VC, tgt_sr 40000, config <rvc_infer.Config object at 0x00000208F7339F50>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-20 20:30:39 | INFO | modules | Select index: 0\n"
     ]
    }
   ],
   "source": [
    "# download and load all models\n",
    "preload_models(\n",
    "    text_use_gpu=True,\n",
    "    text_use_small=False,\n",
    "    text_model_path=semantic_path,\n",
    "    coarse_use_gpu=True,\n",
    "    coarse_use_small=False,\n",
    "    coarse_model_path=coarse_path,\n",
    "    fine_use_gpu=True,\n",
    "    fine_use_small=False,\n",
    "    fine_model_path=fine_path,\n",
    "    codec_use_gpu=True,\n",
    "    force_reload=False,\n",
    "    path=\"models\"\n",
    ")\n",
    "\n",
    "if use_rvc:\n",
    "    from rvc_infer import get_vc, vc_single\n",
    "    vc = get_vc(rvc_path, device, is_half)\n",
    "    vc.get_vc(\"howard-test.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simple generation\n",
    "text_prompt = \"Hello, my name is Serpy. And, uh — and I like pizza. [laughs]\"\n",
    "filepath = \"output/audio.wav\"\n",
    "\n",
    "voice_name = \"howard-clone-from-60sec-sample\" # use your custom voice name here if you have on\n",
    "#audio_array = generate_audio(text_prompt, history_prompt=voice_name, text_temp=0.7, waveform_temp=0.7)\n",
    "#write_wav(filepath, SAMPLE_RATE, audio_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<modules.VC object at 0x00000206252D7910>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\guoho\\.virtualenvs\\bark-with-voice-clone-KGiCdjZF\\Lib\\site-packages\\hydra\\experimental\\initialize.py:43: UserWarning: hydra.experimental.initialize() is no longer experimental. Use hydra.initialize()\n",
      "  deprecation_warning(message=message)\n",
      "C:\\Users\\guoho\\.virtualenvs\\bark-with-voice-clone-KGiCdjZF\\Lib\\site-packages\\hydra\\experimental\\initialize.py:45: UserWarning: \n",
      "The version_base parameter is not specified.\n",
      "Please specify a compatability version level, or None.\n",
      "Will assume defaults for version 1.1\n",
      "  self.delegate = real_initialize(\n",
      "C:\\Users\\guoho\\.virtualenvs\\bark-with-voice-clone-KGiCdjZF\\Lib\\site-packages\\hydra\\experimental\\compose.py:25: UserWarning: hydra.experimental.compose() is no longer experimental. Use hydra.compose()\n",
      "  deprecation_warning(message=message)\n",
      "C:\\Users\\guoho\\.virtualenvs\\bark-with-voice-clone-KGiCdjZF\\Lib\\site-packages\\hydra\\core\\default_element.py:124: UserWarning: In 'config': Usage of deprecated keyword in package header '# @package _group_'.\n",
      "See https://hydra.cc/docs/1.2/upgrades/1.0_to_1.1/changes_to_package_header for more information\n",
      "  deprecation_warning(\n",
      "C:\\Users\\guoho\\.virtualenvs\\bark-with-voice-clone-KGiCdjZF\\Lib\\site-packages\\fairseq\\checkpoint_utils.py:432: UserWarning: \n",
      "'config' is validated against ConfigStore schema with the same name.\n",
      "This behavior is deprecated in Hydra 1.1 and will be removed in Hydra 1.2.\n",
      "See https://hydra.cc/docs/1.2/upgrades/1.0_to_1.1/automatic_schema_matching for migration instructions.\n",
      "  state = load_checkpoint_to_cpu(filename, arg_overrides)\n",
      "C:\\Users\\guoho\\.virtualenvs\\bark-with-voice-clone-KGiCdjZF\\Lib\\site-packages\\hydra\\compose.py:56: UserWarning: \n",
      "The strict flag in the compose API is deprecated.\n",
      "See https://hydra.cc/docs/1.2/upgrades/0.11_to_1.0/strict_mode_flag_deprecated for more info.\n",
      "\n",
      "  deprecation_warning(\n",
      "C:\\Users\\guoho\\Downloads\\bark-with-voice-clone\\Retrieval-based-Voice-Conversion-WebUI\\modules.py:182: UserWarning: \n",
      "'config' is validated against ConfigStore schema with the same name.\n",
      "This behavior is deprecated in Hydra 1.1 and will be removed in Hydra 1.2.\n",
      "See https://hydra.cc/docs/1.2/upgrades/1.0_to_1.1/automatic_schema_matching for migration instructions.\n",
      "  self.hubert_model = load_hubert(self.config)\n",
      "2023-09-20 20:30:48 | INFO | fairseq.tasks.hubert_pretraining | current directory is C:\\Users\\guoho\\Downloads\\bark-with-voice-clone\n",
      "2023-09-20 20:30:48 | INFO | fairseq.tasks.hubert_pretraining | HubertPretrainingTask Config {'_name': 'hubert_pretraining', 'data': '/checkpoint/wnhsu/data/librispeech/960h/iter/250K_50hz_km100_mp0_65_v2', 'fine_tuning': False, 'labels': ['layer6.km500'], 'label_dir': None, 'label_rate': 50.0, 'sample_rate': 16000, 'normalize': False, 'enable_padding': False, 'max_keep_size': None, 'max_sample_size': 250000, 'min_sample_size': 32000, 'single_target': False, 'random_crop': True, 'pad_audio': False}\n",
      "2023-09-20 20:30:48 | INFO | fairseq.models.hubert.hubert | HubertModel Config: {'_name': 'hubert', 'label_rate': 50.0, 'extractor_mode': default, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': gelu, 'layer_type': transformer, 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.0, 'encoder_layerdrop': 0.05, 'dropout_input': 0.1, 'dropout_features': 0.1, 'final_dim': 256, 'untie_final_proj': False, 'layer_norm_first': False, 'conv_feature_layers': '[(512,10,5)] + [(512,3,2)] * 4 + [(512,2,2)] * 2', 'conv_bias': False, 'logit_temp': 0.1, 'target_glu': False, 'feature_grad_mult': 0.1, 'mask_length': 10, 'mask_prob': 0.8, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'conv_pos': 128, 'conv_pos_groups': 16, 'latent_temp': [2.0, 0.5, 0.999995], 'skip_masked': False, 'skip_nomask': False, 'checkpoint_activations': False, 'required_seq_len_multiple': 2, 'depthwise_conv_kernel_size': 31, 'attn_type': '', 'pos_enc_type': 'abs', 'fp16': True}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@@@ len out: 2\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'dtype'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 16\u001b[0m\n\u001b[0;32m     14\u001b[0m         audio_array \u001b[38;5;241m=\u001b[39m vc\u001b[38;5;241m.\u001b[39mvc_single(\u001b[38;5;241m0\u001b[39m,filepath,f0up_key,\u001b[38;5;28;01mNone\u001b[39;00m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpm\u001b[39m\u001b[38;5;124m'\u001b[39m,index_path, \u001b[38;5;28;01mNone\u001b[39;00m, index_rate, filter_radius\u001b[38;5;241m=\u001b[39mfilter_radius, resample_sr\u001b[38;5;241m=\u001b[39mresample_sr, rms_mix_rate\u001b[38;5;241m=\u001b[39mrms_mix_rate, protect\u001b[38;5;241m=\u001b[39mprotect)\n\u001b[0;32m     15\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m@@@ len out: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(audio_array)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 16\u001b[0m     \u001b[43mwrite_wav\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43moutput/vc-out.wav\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mSAMPLE_RATE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maudio_array\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     18\u001b[0m Audio(audio_array, rate\u001b[38;5;241m=\u001b[39mSAMPLE_RATE)\n",
      "File \u001b[1;32m~\\.virtualenvs\\bark-with-voice-clone-KGiCdjZF\\Lib\\site-packages\\scipy\\io\\wavfile.py:772\u001b[0m, in \u001b[0;36mwrite\u001b[1;34m(filename, rate, data)\u001b[0m\n\u001b[0;32m    769\u001b[0m fs \u001b[38;5;241m=\u001b[39m rate\n\u001b[0;32m    771\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 772\u001b[0m     dkind \u001b[38;5;241m=\u001b[39m \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[38;5;241m.\u001b[39mkind\n\u001b[0;32m    773\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (dkind \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mi\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m dkind \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m (dkind \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mu\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[0;32m    774\u001b[0m                                              data\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mitemsize \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m)):\n\u001b[0;32m    775\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnsupported data type \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m data\u001b[38;5;241m.\u001b[39mdtype)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'dtype'"
     ]
    }
   ],
   "source": [
    "print(vc)\n",
    "\n",
    "if use_rvc:\n",
    "    index_rate = 0.75\n",
    "    f0up_key = -6\n",
    "    filter_radius = 3\n",
    "    rms_mix_rate = 0.25\n",
    "    protect = 0.33\n",
    "    resample_sr = SAMPLE_RATE\n",
    "    f0method = \"harvest\" #harvest or pm\n",
    "    try:\n",
    "        audio_array = vc.vc_single(0,filepath,f0up_key,None,f0method,index_path, None, index_rate, filter_radius=filter_radius, resample_sr=resample_sr, rms_mix_rate=rms_mix_rate, protect=protect)\n",
    "    except:\n",
    "        audio_array = vc.vc_single(0,filepath,f0up_key,None,'pm',index_path, None, index_rate, filter_radius=filter_radius, resample_sr=resample_sr, rms_mix_rate=rms_mix_rate, protect=protect)\n",
    "    print(f\"@@@ len out: {len(audio_array)}\")\n",
    "    write_wav(\"output/vc-out.wav\", SAMPLE_RATE, audio_array)\n",
    "\n",
    "Audio(audio_array, rate=SAMPLE_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generation with more control\n",
    "text_prompt = \"Hello, my name is Serpy. And, uh — and I like pizza. [laughs]\"\n",
    "voice_name = \"speaker_0\" # use your custom voice name here if you have on\n",
    "\n",
    "filepath = \"output/audio.wav\"\n",
    "\n",
    "x_semantic = generate_text_semantic(\n",
    "    text_prompt,\n",
    "    history_prompt=voice_name,\n",
    "    temp=0.7,\n",
    "    top_k=50,\n",
    "    top_p=0.95,\n",
    ")\n",
    "\n",
    "x_coarse_gen = generate_coarse(\n",
    "    x_semantic,\n",
    "    history_prompt=voice_name,\n",
    "    temp=0.7,\n",
    "    top_k=50,\n",
    "    top_p=0.95,\n",
    ")\n",
    "x_fine_gen = generate_fine(\n",
    "    x_coarse_gen,\n",
    "    history_prompt=voice_name,\n",
    "    temp=0.5,\n",
    ")\n",
    "audio_array = codec_decode(x_fine_gen)\n",
    "write_wav(filepath, SAMPLE_RATE, audio_array)\n",
    "\n",
    "if use_rvc:\n",
    "    index_rate = 0.75\n",
    "    f0up_key = -6\n",
    "    filter_radius = 3\n",
    "    rms_mix_rate = 0.25\n",
    "    protect = 0.33\n",
    "    resample_sr = SAMPLE_RATE\n",
    "    f0method = \"harvest\" #harvest or pm\n",
    "    try:\n",
    "        audio_array = vc_single(0,filepath,f0up_key,None,f0method,index_path,index_rate, filter_radius=filter_radius, resample_sr=resample_sr, rms_mix_rate=rms_mix_rate, protect=protect)\n",
    "    except:\n",
    "        audio_array = vc_single(0,filepath,f0up_key,None,'pm',index_path,index_rate, filter_radius=filter_radius, resample_sr=resample_sr, rms_mix_rate=rms_mix_rate, protect=protect)\n",
    "    write_wav(filepath, SAMPLE_RATE, audio_array)\n",
    "\n",
    "Audio(audio_array, rate=SAMPLE_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
